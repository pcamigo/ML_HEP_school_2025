{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-hdsitToEwV"
      },
      "source": [
        "# Unsupervised Learning: Clustering\n",
        "\n",
        "This notebook contains an example implementation of DBSCAN\n",
        "\n",
        "Based in Machine learning for physics and Astronomy, Viviana Acquaviva (2023) and Jake Vanderplas' book [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/05.00-machine-learning.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x0c1CRfoEwV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs #create blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxj7Qu-PoEwd"
      },
      "source": [
        "### \"Smiley face\" distribution\n",
        "We generate blobs arranged as a smiley face. The blobs are not convex, that is, for any two points within the set, the line segment connecting them is also entirely within the set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBCKCBJRoEwe"
      },
      "outputs": [],
      "source": [
        "from math import pi, cos, sin\n",
        "from random import random\n",
        "\n",
        "def point(h, k, r):\n",
        "    theta = random() * 2 * pi\n",
        "    return h + cos(theta) * r, k + sin(theta) * r + 0.2*random()\n",
        "\n",
        "xy = [point(1,2,1) for _ in range(100)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKa8kkV8oEwe"
      },
      "outputs": [],
      "source": [
        "X1, y1 = make_blobs(n_samples=10, centers=[(0.5,2.5)],\n",
        "                       cluster_std=0.05, random_state=1)\n",
        "\n",
        "X2, y2 = make_blobs(n_samples=10, centers=[(1.5,2.5)],\n",
        "                       cluster_std=0.05, random_state=2)\n",
        "\n",
        "X3, y3 = make_blobs(n_samples=10, centers=[(1,1.7)],\n",
        "                       cluster_std=0.05, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY3KgbXJoEwe"
      },
      "outputs": [],
      "source": [
        "X3_stretch = np.array([X3[:,0]*3, X3[:,1]]) #for the mouth :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1xfAyoZoEwg"
      },
      "outputs": [],
      "source": [
        "plt.axes().set_aspect('equal', 'datalim')\n",
        "plt.scatter(*zip(*xy))\n",
        "plt.scatter(X1[:,0],X1[:,1])\n",
        "plt.scatter(X2[:,0],X2[:,1])\n",
        "plt.scatter(X3_stretch.T[:,0]-1.9,X3_stretch.T[:,1])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE4PHbZsoEwh"
      },
      "source": [
        "All the sets of points in just the array X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk9uulbZoEwh"
      },
      "outputs": [],
      "source": [
        "X = np.vstack([xy,X1,X2,np.array([X3_stretch.T[:,0]-1.9,X3_stretch.T[:,1]]).T])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_iOX_D_aGzE"
      },
      "outputs": [],
      "source": [
        "#X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2w6wxFcoEwh"
      },
      "source": [
        "### Clustering with k-means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpUhI0NhoEwh"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters=4, n_init = 10, random_state=32) #you can change k as you wish\n",
        "kmeans.fit(X)\n",
        "y_kmeans = kmeans.predict(X)\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=10, cmap='viridis')\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=100, alpha=0.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muxxgCiYaGzF"
      },
      "source": [
        "These blobs we created are not convex and do not have a globular shape, so K-means does not perform well.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7pttxJuoEwk"
      },
      "source": [
        "###  Now with DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54zbilKIoEwk"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "#Code adapted from: https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLgxLeZ5oEwk"
      },
      "source": [
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clustering algorithm that identifies dense areas of points in the data space as clusters, allowing the detection of groups of any shape while isolating points that do not belong to any cluster (outliers). It uses two key parameters: eps (the maximum distance to consider points as neighbors) and min_samples (the minimum number of neighbors required for a point to be considered a core point). Clusters are built recursively from core points connected by nearby neighbors, while points in low-density areas are identified as outliers. This makes DBSCAN particularly useful for data where clusters are not globular or convex and where noise or isolated points are present.\n",
        "\n",
        "In each iteration, DBSCAN selects a point and evaluates whether it has enough neighbors within the eps distance to qualify as a core point. If it is a core point, the cluster expands to include all its direct neighbors and their core neighbors recursively. If the point does not have enough neighbors, it is marked as a potential outlier. The process repeats until all points are classified into clusters or labeled as outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXUOwEVcoEwl"
      },
      "outputs": [],
      "source": [
        "# #############################################################################\n",
        "# Calculate DBSCAN\n",
        "db = DBSCAN(eps=0.25, min_samples=2).fit(X) #parameters: eps and min_samples\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "labels = db.labels_\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present.\n",
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "n_noise_ = list(labels).count(-1)\n",
        "\n",
        "print('Estimated number of clusters: %d' % n_clusters_)\n",
        "print('Estimated number of noise points: %d' % n_noise_)\n",
        "\n",
        "# #############################################################################\n",
        "\n",
        "#\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each)\n",
        "          for each in np.linspace(0, 1, len(unique_labels))]\n",
        "for k, col in zip(unique_labels, colors):\n",
        "    if k == -1:\n",
        "        col = [0, 0, 0, 1]\n",
        "\n",
        "    class_member_mask = (labels == k)\n",
        "\n",
        "    xy = X[class_member_mask & core_samples_mask]\n",
        "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=14)\n",
        "\n",
        "    xy = X[class_member_mask & ~core_samples_mask]\n",
        "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=6)\n",
        "\n",
        "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUxcUP0woEwl"
      },
      "source": [
        "Let's see how the results change if we change the values of `eps` parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POW9hDiWoEwl",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# #############################################################################\n",
        "# Calculate DBSCAN\n",
        "\n",
        "for i,eps in enumerate([0.2, 0.25, 0.3, 0.35]): #iterates for several eps values\n",
        "\n",
        "    plt.figure(figsize = (6,6))\n",
        "\n",
        "    db = DBSCAN(eps=eps, min_samples=2).fit(X)\n",
        "\n",
        "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "    core_samples_mask[db.core_sample_indices_] = True\n",
        "    labels = db.labels_\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present\n",
        "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    n_noise_ = list(labels).count(-1)\n",
        "\n",
        "    print('Estimated number of clusters: %d' % n_clusters_)\n",
        "    print('Estimated number of noise points: %d' % n_noise_)\n",
        "\n",
        "# #############################################################################\n",
        "\n",
        "\n",
        "\n",
        "    unique_labels = set(labels)\n",
        "    colors = [plt.cm.Spectral(each)\n",
        "          for each in np.linspace(0, 1, len(unique_labels))]\n",
        "    for k, col in zip(unique_labels, colors):\n",
        "        if k == -1:\n",
        "        # Black used for noise.\n",
        "            col = [0, 0, 0, 1]\n",
        "\n",
        "        class_member_mask = (labels == k)\n",
        "\n",
        "        xy = X[class_member_mask & core_samples_mask]\n",
        "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=10)\n",
        "\n",
        "        xy = X[class_member_mask & ~core_samples_mask]\n",
        "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=6)\n",
        "\n",
        "    plt.title('$\\epsilon$ = %0.2f; estimated number of clusters: %d' % (eps, n_clusters_))\n",
        "\n",
        "    plt.savefig('DBSCAN_'+str(i)+'.pdf', dpi = 300)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdOUgURuoEwn"
      },
      "source": [
        "The conclusion here is that a clustering scheme and its evaluation are challenging. To make sense of the clustering scheme, we need some understanding of the structure of our dataâ€”but this is precisely what we aim to uncover when applying clustering. These algorithms and their results must be approached with caution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "562aTUoIoEwq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}